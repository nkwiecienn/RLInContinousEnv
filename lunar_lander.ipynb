{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Due to many problems it is strongly advised to use Python 3.9 and the packages' versions specified in the requirements.**",
   "id": "5ca975f56e6fe989"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T10:20:31.399785Z",
     "start_time": "2025-05-31T10:20:31.380526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import cv2\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboard\n",
    "from tbparse import SummaryReader\n",
    "import torch as th\n",
    "import torch.nn as nn"
   ],
   "id": "5a9ec3ec31dbf47a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example for a game with random moves",
   "id": "490bf70da7f0313b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-30T17:53:42.466605Z",
     "start_time": "2025-05-30T17:53:36.062548Z"
    }
   },
   "source": [
    "env = gym.make(\n",
    "    \"LunarLanderContinuous-v3\",\n",
    "    continuous = True,\n",
    "    gravity = -10.0,\n",
    "    enable_wind = False,\n",
    "    wind_power = 15.0,\n",
    "    turbulence_power = 1.5,\n",
    "    render_mode=\"rgb_array\"\n",
    ")\n",
    "\n",
    "state, _ = env.reset()\n",
    "terminated = False\n",
    "truncated = False\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "    frame = env.render()\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    cv2.waitKey(50)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Example for using SAC from stable_baselines3 for the Lunar Lander Problem",
   "id": "bb06297286e746cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T17:56:13.957359Z",
     "start_time": "2025-05-30T17:53:42.529584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10000, log_interval=4)"
   ],
   "id": "7d750e36bd8bf641",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 111      |\n",
      "|    ep_rew_mean     | -246     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 101      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 443      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.184    |\n",
      "|    critic_loss     | 25.2     |\n",
      "|    ent_coef        | 0.908    |\n",
      "|    ent_coef_loss   | -0.241   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 342      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 128      |\n",
      "|    ep_rew_mean     | -163     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 1021     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.24     |\n",
      "|    critic_loss     | 12.6     |\n",
      "|    ent_coef        | 0.776    |\n",
      "|    ent_coef_loss   | -0.591   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 920      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 151      |\n",
      "|    ep_rew_mean     | -161     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 1810     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0887   |\n",
      "|    critic_loss     | 12.1     |\n",
      "|    ent_coef        | 0.626    |\n",
      "|    ent_coef_loss   | -1.03    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1709     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 170      |\n",
      "|    ep_rew_mean     | -177     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 2716     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.419    |\n",
      "|    critic_loss     | 13.8     |\n",
      "|    ent_coef        | 0.491    |\n",
      "|    ent_coef_loss   | -1.39    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 2615     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 263      |\n",
      "|    ep_rew_mean     | -169     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 73       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 5268     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.58    |\n",
      "|    critic_loss     | 3.05     |\n",
      "|    ent_coef        | 0.265    |\n",
      "|    ent_coef_loss   | -1.76    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5167     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 383      |\n",
      "|    ep_rew_mean     | -140     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 67       |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 9191     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.17    |\n",
      "|    critic_loss     | 3.87     |\n",
      "|    ent_coef        | 0.0909   |\n",
      "|    ent_coef_loss   | -1.72    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9090     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x24f9b55f970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T17:56:21.500520Z",
     "start_time": "2025-05-30T17:56:14.039142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "obs, info = env.reset()\n",
    "terminated = False\n",
    "truncated = False\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "    frame = env.render()\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "    cv2.waitKey(50)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "793e24a8c7b452f4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "The best hyperparameters for this problem can be found at https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/sac.yml:\n",
    "\n",
    "```yml\n",
    "LunarLanderContinuous-v3:\n",
    "  n_timesteps: !!float 5e5\n",
    "  policy: 'MlpPolicy'\n",
    "  batch_size: 256\n",
    "  learning_rate: lin_7.3e-4\n",
    "  buffer_size: 1000000\n",
    "  ent_coef: 'auto'\n",
    "  gamma: 0.99\n",
    "  tau: 0.01\n",
    "  train_freq: 1\n",
    "  gradient_steps: 1\n",
    "  learning_starts: 10000\n",
    "  policy_kwargs: \"dict(net_arch=[400, 300])\"\n",
    "```\n",
    "\n",
    "It is safe to assume that those are the most important hyperparameters for training. Here is a brief description of each one:\n",
    "- *n_timesteps* - total number of time steps to train the model;\n",
    "- *policy* - choice of neural network (MlpPolicy means Multi-Layer Perceptron policy);\n",
    "- *policy_kwargs* - the architecture of the network (here [400, 300] means two hidden layers with 400 and 300 neurons);\n",
    "- *batch_size* - number of samples per training update;\n",
    "- *learning_rate* - a linear schedule for learning rate (here starting at 7.3e-3 and decreasing linearly to 0 over training);\n",
    "- *learning_starts* - the agent collects n steps before starting to learn;\n",
    "- *ent-coef* - balance between exploration and exploitation (here is learnt automatically);\n",
    "- *gamma* - discount factor for future rewards;\n",
    "- *tau* - controls the soft update speed of the target networks;\n",
    "- *train_freq* - the model is trained every n steps;\n",
    "- *gradient_steps* - how many gradient steps are done after each rollout."
   ],
   "id": "1f799168e760edb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T02:12:07.743602Z",
     "start_time": "2025-05-30T18:57:13.014341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_runs = 10\n",
    "timesteps = 50000\n",
    "\n",
    "param_sets = [\n",
    "    {\"learning_rate\": 3e-4, \"batch_size\": 256},\n",
    "    {\"learning_rate\": 7.3e-4, \"batch_size\": 256},\n",
    "    {\"learning_rate\": 1e-3, \"batch_size\": 128},\n",
    "]\n",
    "\n",
    "log_root = \"./logs\"\n",
    "\n",
    "for i, params in enumerate(param_sets):\n",
    "    for run in range(n_runs):\n",
    "        env = gym.make(\"LunarLanderContinuous-v3\", render_mode=\"rgb_array\")\n",
    "        env = Monitor(env)\n",
    "\n",
    "        model = SAC(\n",
    "            \"MlpPolicy\",\n",
    "            env,\n",
    "            verbose=0,\n",
    "            seed=run,\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            tensorboard_log=f\"{log_root}/set_{i}\",\n",
    "        )\n",
    "\n",
    "        model.learn(total_timesteps=timesteps, tb_log_name=f\"run_{run}\")\n",
    "        env.close()"
   ],
   "id": "75ccfff6de4b849c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Learning curves",
   "id": "7dbdd7d8eecf740f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T08:36:14.555433Z",
     "start_time": "2025-05-31T08:36:13.399035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_root = \"./logs\"\n",
    "param_sets = 3\n",
    "output_dir = \"./plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_rewards_from_tensorboard(log_dir):\n",
    "    rewards = []\n",
    "    for run_dir in os.listdir(log_dir):\n",
    "        full_path = os.path.join(log_dir, run_dir)\n",
    "        reader = SummaryReader(full_path)\n",
    "        df = reader.scalars\n",
    "        reward_df = df[df['tag'] == 'rollout/ep_rew_mean']\n",
    "        rewards.append((reward_df['step'].values, reward_df['value'].values))\n",
    "\n",
    "    return rewards\n",
    "\n",
    "all_sets_data = []\n",
    "\n",
    "for i in range(param_sets):\n",
    "    reward_curves = load_rewards_from_tensorboard(f\"{log_root}/set_{i}\")\n",
    "\n",
    "    all_x = sorted(set(x for steps, _ in reward_curves for x in steps))\n",
    "    all_x = np.array(all_x)\n",
    "\n",
    "    aligned_rewards = []\n",
    "    for steps, values in reward_curves:\n",
    "        interp_values = np.interp(all_x, steps, values)\n",
    "        aligned_rewards.append(interp_values)\n",
    "\n",
    "    aligned_rewards = np.array(aligned_rewards)\n",
    "    mean_rewards = np.mean(aligned_rewards, axis=0)\n",
    "    std_rewards = np.std(aligned_rewards, axis=0)\n",
    "\n",
    "    all_sets_data.append((all_x, mean_rewards, std_rewards))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(all_x, mean_rewards, label=f\"Set {i}\")\n",
    "    plt.fill_between(all_x, mean_rewards - std_rewards, mean_rewards + std_rewards, alpha=0.3)\n",
    "    plt.title(f\"Learning Curve for Hyperparameter Set {i}\")\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Episode Reward\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/set_{i}.png\")\n",
    "    plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, (x, mean, std) in enumerate(all_sets_data):\n",
    "    plt.plot(x, mean, label=f\"Set {i}\")\n",
    "    plt.fill_between(x, mean - std, mean + std, alpha=0.3)\n",
    "plt.title(\"Combined Learning Curves\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Episode Reward\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/combined.png\")\n",
    "plt.close()"
   ],
   "id": "5020973ca6b88bc6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Stable Baseline3 Zoo model\n",
    "For comparison here's the recommended hyperparameters."
   ],
   "id": "eb7c05ad676329b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T10:09:14.849580Z",
     "start_time": "2025-05-31T09:51:11.872032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gym.make(\"LunarLanderContinuous-v3\", render_mode=\"rgb_array\")\n",
    "env = Monitor(env)\n",
    "\n",
    "ideal_log_dir = \"./logs/ideal\"\n",
    "os.makedirs(ideal_log_dir, exist_ok=True)\n",
    "\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    batch_size=256,\n",
    "    learning_rate=lambda _: 7.3e-4 * _,\n",
    "    buffer_size=100000,\n",
    "    ent_coef=\"auto\",\n",
    "    gamma=0.99,\n",
    "    tau=0.01,\n",
    "    train_freq=1,\n",
    "    gradient_steps=1,\n",
    "    learning_starts=10000,\n",
    "    policy_kwargs=dict(net_arch=[400, 300]),\n",
    "    tensorboard_log=ideal_log_dir,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=50000, tb_log_name=\"run_0\")\n",
    "env.close()"
   ],
   "id": "75e95ed1871300d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/ideal\\run_0_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | -344     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 2623     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 414      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 115      |\n",
      "|    ep_rew_mean     | -329     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 2736     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 922      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -279     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 2670     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1315     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -262     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 2799     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1712     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -253     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 2872     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2112     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -237     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 2932     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2594     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -233     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 2984     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3019     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -231     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 3022     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3382     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -216     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 3047     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3845     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -222     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 3068     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4278     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -233     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 3076     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4725     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -233     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 3089     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5111     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 3096     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5490     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -227     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 3091     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5934     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -231     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 3090     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 6360     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -229     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 3068     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 6870     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -225     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 3079     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7288     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -221     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 3021     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7666     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 2992     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8116     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -220     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 2979     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8486     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -222     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 2963     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8932     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 2963     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 9347     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 2971     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 9820     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -217     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 1126     |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 10327    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.6      |\n",
      "|    critic_loss     | 4.96     |\n",
      "|    ent_coef        | 0.833    |\n",
      "|    ent_coef_loss   | -0.543   |\n",
      "|    learning_rate   | 0.000579 |\n",
      "|    n_updates       | 326      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 526      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 10992    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.35     |\n",
      "|    critic_loss     | 13.2     |\n",
      "|    ent_coef        | 0.592    |\n",
      "|    ent_coef_loss   | -1.15    |\n",
      "|    learning_rate   | 0.00057  |\n",
      "|    n_updates       | 991      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 126      |\n",
      "|    ep_rew_mean     | -204     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 200      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 12984    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.33     |\n",
      "|    critic_loss     | 170      |\n",
      "|    ent_coef        | 0.26     |\n",
      "|    ent_coef_loss   | -0.84    |\n",
      "|    learning_rate   | 0.00054  |\n",
      "|    n_updates       | 2983     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 134      |\n",
      "|    ep_rew_mean     | -190     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 99       |\n",
      "|    total_timesteps | 14339    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.98    |\n",
      "|    critic_loss     | 8.91     |\n",
      "|    ent_coef        | 0.174    |\n",
      "|    ent_coef_loss   | -1.09    |\n",
      "|    learning_rate   | 0.000521 |\n",
      "|    n_updates       | 4338     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 149      |\n",
      "|    ep_rew_mean     | -184     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 110      |\n",
      "|    time_elapsed    | 146      |\n",
      "|    total_timesteps | 16210    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.78     |\n",
      "|    critic_loss     | 27.4     |\n",
      "|    ent_coef        | 0.127    |\n",
      "|    ent_coef_loss   | -0.165   |\n",
      "|    learning_rate   | 0.000493 |\n",
      "|    n_updates       | 6209     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 164      |\n",
      "|    ep_rew_mean     | -171     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 198      |\n",
      "|    total_timesteps | 18129    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.844   |\n",
      "|    critic_loss     | 12       |\n",
      "|    ent_coef        | 0.134    |\n",
      "|    ent_coef_loss   | -0.389   |\n",
      "|    learning_rate   | 0.000465 |\n",
      "|    n_updates       | 8128     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 176      |\n",
      "|    ep_rew_mean     | -163     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 19703    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.17    |\n",
      "|    critic_loss     | 14.3     |\n",
      "|    ent_coef        | 0.144    |\n",
      "|    ent_coef_loss   | 0.545    |\n",
      "|    learning_rate   | 0.000442 |\n",
      "|    n_updates       | 9702     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | -150     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 72       |\n",
      "|    time_elapsed    | 301      |\n",
      "|    total_timesteps | 22005    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.19    |\n",
      "|    critic_loss     | 3.98     |\n",
      "|    ent_coef        | 0.154    |\n",
      "|    ent_coef_loss   | -0.0436  |\n",
      "|    learning_rate   | 0.000409 |\n",
      "|    n_updates       | 12004    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | -136     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 68       |\n",
      "|    time_elapsed    | 345      |\n",
      "|    total_timesteps | 23802    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.89    |\n",
      "|    critic_loss     | 9.46     |\n",
      "|    ent_coef        | 0.156    |\n",
      "|    ent_coef_loss   | 0.0663   |\n",
      "|    learning_rate   | 0.000383 |\n",
      "|    n_updates       | 13801    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | -125     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 65       |\n",
      "|    time_elapsed    | 396      |\n",
      "|    total_timesteps | 25875    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 11.2     |\n",
      "|    ent_coef        | 0.149    |\n",
      "|    ent_coef_loss   | 0.0312   |\n",
      "|    learning_rate   | 0.000352 |\n",
      "|    n_updates       | 15874    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | -123     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 61       |\n",
      "|    time_elapsed    | 469      |\n",
      "|    total_timesteps | 28669    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 5.56     |\n",
      "|    ent_coef        | 0.138    |\n",
      "|    ent_coef_loss   | -0.965   |\n",
      "|    learning_rate   | 0.000311 |\n",
      "|    n_updates       | 18668    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | -111     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 57       |\n",
      "|    time_elapsed    | 544      |\n",
      "|    total_timesteps | 31376    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.1    |\n",
      "|    critic_loss     | 15.1     |\n",
      "|    ent_coef        | 0.121    |\n",
      "|    ent_coef_loss   | 0.0118   |\n",
      "|    learning_rate   | 0.000272 |\n",
      "|    n_updates       | 21375    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 285      |\n",
      "|    ep_rew_mean     | -93.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 54       |\n",
      "|    time_elapsed    | 604      |\n",
      "|    total_timesteps | 33190    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.1    |\n",
      "|    critic_loss     | 4.75     |\n",
      "|    ent_coef        | 0.121    |\n",
      "|    ent_coef_loss   | -0.0445  |\n",
      "|    learning_rate   | 0.000245 |\n",
      "|    n_updates       | 23189    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 301      |\n",
      "|    ep_rew_mean     | -76.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 662      |\n",
      "|    total_timesteps | 35254    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.2    |\n",
      "|    critic_loss     | 4.93     |\n",
      "|    ent_coef        | 0.123    |\n",
      "|    ent_coef_loss   | -0.0879  |\n",
      "|    learning_rate   | 0.000215 |\n",
      "|    n_updates       | 25253    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 319      |\n",
      "|    ep_rew_mean     | -68.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 720      |\n",
      "|    total_timesteps | 37422    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.9    |\n",
      "|    critic_loss     | 8.03     |\n",
      "|    ent_coef        | 0.121    |\n",
      "|    ent_coef_loss   | -0.594   |\n",
      "|    learning_rate   | 0.000184 |\n",
      "|    n_updates       | 27421    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 330      |\n",
      "|    ep_rew_mean     | -58.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 765      |\n",
      "|    total_timesteps | 38968    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.4    |\n",
      "|    critic_loss     | 11       |\n",
      "|    ent_coef        | 0.114    |\n",
      "|    ent_coef_loss   | -0.58    |\n",
      "|    learning_rate   | 0.000161 |\n",
      "|    n_updates       | 28967    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 350      |\n",
      "|    ep_rew_mean     | -38.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 49       |\n",
      "|    time_elapsed    | 836      |\n",
      "|    total_timesteps | 41379    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20.3    |\n",
      "|    critic_loss     | 2.95     |\n",
      "|    ent_coef        | 0.113    |\n",
      "|    ent_coef_loss   | 0.0562   |\n",
      "|    learning_rate   | 0.000126 |\n",
      "|    n_updates       | 31378    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 372      |\n",
      "|    ep_rew_mean     | -28      |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 48       |\n",
      "|    time_elapsed    | 911      |\n",
      "|    total_timesteps | 44075    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.2    |\n",
      "|    critic_loss     | 4.96     |\n",
      "|    ent_coef        | 0.122    |\n",
      "|    ent_coef_loss   | -0.0277  |\n",
      "|    learning_rate   | 8.65e-05 |\n",
      "|    n_updates       | 34074    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 398      |\n",
      "|    ep_rew_mean     | -14.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 47       |\n",
      "|    time_elapsed    | 998      |\n",
      "|    total_timesteps | 47046    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.2    |\n",
      "|    critic_loss     | 32.8     |\n",
      "|    ent_coef        | 0.117    |\n",
      "|    ent_coef_loss   | -0.616   |\n",
      "|    learning_rate   | 4.31e-05 |\n",
      "|    n_updates       | 37045    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File or directory not found: ./logs/ideal/run_0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 29\u001B[0m\n\u001B[0;32m     25\u001B[0m env\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m     27\u001B[0m ideal_tb_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./logs/ideal/run_0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 29\u001B[0m reader \u001B[38;5;241m=\u001B[39m \u001B[43mSummaryReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mideal_tb_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m df \u001B[38;5;241m=\u001B[39m reader\u001B[38;5;241m.\u001B[39mscalars\n\u001B[0;32m     32\u001B[0m reward_df \u001B[38;5;241m=\u001B[39m df[df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtag\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrollout/ep_rew_mean\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\RL\\GamesWithRL\\.venv\\lib\\site-packages\\tbparse\\summary_reader.py:143\u001B[0m, in \u001B[0;36mSummaryReader.__init__\u001B[1;34m(self, log_path, pivot, extra_columns, event_types)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Stores a `pandas.DataFrame` containing all events.\"\"\"\u001B[39;00m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_path):\n\u001B[1;32m--> 143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFile or directory not found: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_path):\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;66;03m# Note: tensorflow.python.summary.summary_iterator is less\u001B[39;00m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;66;03m#       straightforward, so we use EventAccumulator instead.\u001B[39;00m\n\u001B[0;32m    147\u001B[0m     size_guidance \u001B[38;5;241m=\u001B[39m MINIMUM_SIZE_GUIDANCE\u001B[38;5;241m.\u001B[39mcopy()\n",
      "\u001B[1;31mValueError\u001B[0m: File or directory not found: ./logs/ideal/run_0"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T10:17:58.094822Z",
     "start_time": "2025-05-31T10:17:57.914451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ideal_tb_dir = \"./logs/ideal/run_0_2\"\n",
    "\n",
    "reader = SummaryReader(ideal_tb_dir)\n",
    "df = reader.scalars\n",
    "\n",
    "reward_df = df[df[\"tag\"] == \"rollout/ep_rew_mean\"]\n",
    "timesteps = reward_df[\"step\"].values\n",
    "rewards = reward_df[\"value\"].values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timesteps, rewards, label=\"Ideal Parameters\")\n",
    "plt.title(\"Learning Curve (Ideal Parameters)\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Episode Reward\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = \"./plots/ideal.png\"\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ],
   "id": "98ce9388d888e5b7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T10:13:41.499815Z",
     "start_time": "2025-05-31T10:13:41.444044Z"
    }
   },
   "cell_type": "code",
   "source": "model.save(\"ideal_sac_model\")",
   "id": "ef75217d5252427f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Testing different network architectures\n",
    "\n",
    "In Stable Baselines3 the network architecture can be controlled with policies. The information about them and the default values can be found here:\n",
    "\n",
    "https://stable-baselines3.readthedocs.io/en/master/_modules/stable_baselines3/sac/policies.html\n",
    "\n",
    "In the \"ideal\" example the architecture of the network (Multi-Layer Perceptron) is:\n",
    "- 2 hidden layers - first with 400 units and second with 300 units;\n",
    "- ReLu activation.\n",
    "\n",
    "To test a different architecture all other hyperparameters will be kept the same except for the architecture which will be:\n",
    "- 3 hidden layers - 256, 256 and 128 units respectively;\n",
    "- Tanh activation."
   ],
   "id": "adfceb6b87a9042d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T10:34:59.141519Z",
     "start_time": "2025-05-31T10:21:28.709750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gym.make(\"LunarLanderContinuous-v3\", render_mode=\"rgb_array\")\n",
    "env = Monitor(env)\n",
    "\n",
    "changed_log_dir = \"./logs/changed_network\"\n",
    "os.makedirs(changed_log_dir, exist_ok=True)\n",
    "\n",
    "model = SAC(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    batch_size=256,\n",
    "    learning_rate=lambda _: 7.3e-4 * _,\n",
    "    buffer_size=100000,\n",
    "    ent_coef=\"auto\",\n",
    "    gamma=0.99,\n",
    "    tau=0.01,\n",
    "    train_freq=1,\n",
    "    gradient_steps=1,\n",
    "    learning_starts=10000,\n",
    "    policy_kwargs=dict(net_arch=[256, 256, 128], activation_fn=nn.Tanh),\n",
    "    tensorboard_log=changed_log_dir,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=50000, tb_log_name=\"run_0\")\n",
    "env.close()"
   ],
   "id": "4432ac65c80ef80a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/changed_network\\run_0_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 117      |\n",
      "|    ep_rew_mean     | -218     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 2299     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 468      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -186     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 2540     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 868      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -214     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 2496     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1352     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -226     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 2609     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 1750     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 114      |\n",
      "|    ep_rew_mean     | -196     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 2687     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2271     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 114      |\n",
      "|    ep_rew_mean     | -189     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 2735     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2742     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -188     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 2785     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3157     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -198     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 2817     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 3615     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -191     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 2808     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4025     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 2805     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4380     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -192     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 2805     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 4778     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -192     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 2811     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5234     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -203     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 2819     |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 5615     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -199     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 2842     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 5970     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -197     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 2855     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 6411     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 105      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 2870     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 6749     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 2806     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7269     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 2777     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 7644     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -201     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 2784     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 8070     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 106      |\n",
      "|    ep_rew_mean     | -196     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 2780     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8480     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -194     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 2800     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 8952     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 2806     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 9447     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 107      |\n",
      "|    ep_rew_mean     | -195     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 2816     |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 9853     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 108      |\n",
      "|    ep_rew_mean     | -193     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 1071     |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 10404    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.647   |\n",
      "|    critic_loss     | 28.9     |\n",
      "|    ent_coef        | 0.798    |\n",
      "|    ent_coef_loss   | -0.653   |\n",
      "|    learning_rate   | 0.000578 |\n",
      "|    n_updates       | 403      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 112      |\n",
      "|    ep_rew_mean     | -190     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 506      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 11203    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.8     |\n",
      "|    critic_loss     | 59.7     |\n",
      "|    ent_coef        | 0.533    |\n",
      "|    ent_coef_loss   | -1.3     |\n",
      "|    learning_rate   | 0.000566 |\n",
      "|    n_updates       | 1202     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 124      |\n",
      "|    ep_rew_mean     | -185     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 259      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 12834    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.29    |\n",
      "|    critic_loss     | 6.82     |\n",
      "|    ent_coef        | 0.275    |\n",
      "|    ent_coef_loss   | -1.35    |\n",
      "|    learning_rate   | 0.000543 |\n",
      "|    n_updates       | 2833     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 153      |\n",
      "|    ep_rew_mean     | -184     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 109      |\n",
      "|    total_timesteps | 16164    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.8     |\n",
      "|    critic_loss     | 16.6     |\n",
      "|    ent_coef        | 0.119    |\n",
      "|    ent_coef_loss   | 0.0883   |\n",
      "|    learning_rate   | 0.000494 |\n",
      "|    n_updates       | 6163     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | -175     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 108      |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 20164    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.7    |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    ent_coef        | 0.101    |\n",
      "|    ent_coef_loss   | -0.603   |\n",
      "|    learning_rate   | 0.000436 |\n",
      "|    n_updates       | 10163    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 217      |\n",
      "|    ep_rew_mean     | -163     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 250      |\n",
      "|    total_timesteps | 23447    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.4    |\n",
      "|    critic_loss     | 9.76     |\n",
      "|    ent_coef        | 0.0992   |\n",
      "|    ent_coef_loss   | -0.0863  |\n",
      "|    learning_rate   | 0.000388 |\n",
      "|    n_updates       | 13446    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 246      |\n",
      "|    ep_rew_mean     | -160     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 322      |\n",
      "|    total_timesteps | 26914    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.4    |\n",
      "|    critic_loss     | 5.85     |\n",
      "|    ent_coef        | 0.0885   |\n",
      "|    ent_coef_loss   | 0.192    |\n",
      "|    learning_rate   | 0.000337 |\n",
      "|    n_updates       | 16913    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 282      |\n",
      "|    ep_rew_mean     | -155     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 76       |\n",
      "|    time_elapsed    | 406      |\n",
      "|    total_timesteps | 30914    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22      |\n",
      "|    critic_loss     | 6.14     |\n",
      "|    ent_coef        | 0.091    |\n",
      "|    ent_coef_loss   | 0.218    |\n",
      "|    learning_rate   | 0.000279 |\n",
      "|    n_updates       | 20913    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 310      |\n",
      "|    ep_rew_mean     | -149     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 72       |\n",
      "|    time_elapsed    | 472      |\n",
      "|    total_timesteps | 34127    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.5    |\n",
      "|    critic_loss     | 25.1     |\n",
      "|    ent_coef        | 0.0941   |\n",
      "|    ent_coef_loss   | -0.638   |\n",
      "|    learning_rate   | 0.000232 |\n",
      "|    n_updates       | 24126    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 323      |\n",
      "|    ep_rew_mean     | -147     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 70       |\n",
      "|    time_elapsed    | 505      |\n",
      "|    total_timesteps | 35869    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.6    |\n",
      "|    critic_loss     | 3.38     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | 0.0248   |\n",
      "|    learning_rate   | 0.000206 |\n",
      "|    n_updates       | 25868    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | -146     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 68       |\n",
      "|    time_elapsed    | 571      |\n",
      "|    total_timesteps | 39121    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.6    |\n",
      "|    critic_loss     | 20.1     |\n",
      "|    ent_coef        | 0.0932   |\n",
      "|    ent_coef_loss   | 0.0759   |\n",
      "|    learning_rate   | 0.000159 |\n",
      "|    n_updates       | 29120    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 379      |\n",
      "|    ep_rew_mean     | -142     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 65       |\n",
      "|    time_elapsed    | 640      |\n",
      "|    total_timesteps | 42234    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.2    |\n",
      "|    critic_loss     | 6.37     |\n",
      "|    ent_coef        | 0.0994   |\n",
      "|    ent_coef_loss   | -0.309   |\n",
      "|    learning_rate   | 0.000113 |\n",
      "|    n_updates       | 32233    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | -131     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 64       |\n",
      "|    time_elapsed    | 695      |\n",
      "|    total_timesteps | 44731    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.5    |\n",
      "|    critic_loss     | 8.9      |\n",
      "|    ent_coef        | 0.0916   |\n",
      "|    ent_coef_loss   | -0.396   |\n",
      "|    learning_rate   | 7.69e-05 |\n",
      "|    n_updates       | 34730    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 434      |\n",
      "|    ep_rew_mean     | -126     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 62       |\n",
      "|    time_elapsed    | 780      |\n",
      "|    total_timesteps | 48640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.3    |\n",
      "|    critic_loss     | 14.7     |\n",
      "|    ent_coef        | 0.0796   |\n",
      "|    ent_coef_loss   | -0.0107  |\n",
      "|    learning_rate   | 1.99e-05 |\n",
      "|    n_updates       | 38639    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T10:46:07.214898Z",
     "start_time": "2025-05-31T10:46:07.020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ideal_tb_dir = \"./logs/changed_network/run_0_1\"\n",
    "\n",
    "reader = SummaryReader(ideal_tb_dir)\n",
    "df = reader.scalars\n",
    "\n",
    "reward_df = df[df[\"tag\"] == \"rollout/ep_rew_mean\"]\n",
    "timesteps = reward_df[\"step\"].values\n",
    "rewards = reward_df[\"value\"].values\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timesteps, rewards, label=\"Ideal Parameters with changed network\")\n",
    "plt.title(\"Learning Curve (Ideal Parameters with changed network)\")\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Episode Reward\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "output_path = \"./plots/changed_network.png\"\n",
    "plt.savefig(output_path)\n",
    "plt.close()"
   ],
   "id": "5d26c6fd15c140ef",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Running the model with deterministic actions",
   "id": "2c28f27383eee1c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T11:12:50.533662Z",
     "start_time": "2025-05-31T11:12:33.169207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gym.make(\"LunarLanderContinuous-v3\", render_mode=\"rgb_array\")\n",
    "env = Monitor(env)\n",
    "\n",
    "model = SAC.load(\"ideal_sac_model\")\n",
    "model.set_env(env)\n",
    "\n",
    "rewards = []\n",
    "\n",
    "for i in range(10):\n",
    "    state, _ = env.reset()\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "    total_reward = 0.0\n",
    "    while not (terminated or truncated):\n",
    "        action, _ = model.predict(state, deterministic=True)\n",
    "        state, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "    rewards.append(total_reward)\n",
    "\n",
    "print(\"Mean reward:\", sum(rewards) / len(rewards))\n"
   ],
   "id": "8395a806a6dc4621",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "Mean reward: 86.20785724310558\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
